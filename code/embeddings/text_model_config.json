{
    "bert-base": {
        "huggingface_hub": "bert-base-uncased",
        "model_type": "encoder",
        "num_layers": 12
    },
    "bert-large": {
        "huggingface_hub": "bert-large-uncased",
        "model_type": "encoder",
        "num_layers": 24
    },
    "t5-small": {
        "huggingface_hub": "t5-small",
        "model_type": "encoder-decoder",
        "num_layers": 6
    },
    "t5-base": {
        "huggingface_hub": "t5-base",
        "model_type": "encoder-decoder",
        "num_layers": 12
    },
    "t5-large": {
        "huggingface_hub": "t5-large",
        "model_type": "encoder-decoder",
        "num_layers": 24
    },
    "gpt2": {
        "huggingface_hub": "gpt2",
        "model_type": "decoder",
        "num_layers": 12
    },
    "gpt2-medium": {
        "huggingface_hub": "openai-community/gpt2-medium",
        "model_type": "decoder",
        "num_layers": 24
    },
    "gpt2-large": {
        "huggingface_hub": "openai-community/gpt2-large",
        "model_type": "decoder",
        "num_layers": 36
    },
    "bart-base": {
        "huggingface_hub": "facebook/bart-base",
        "model_type": "encoder-decoder",
        "num_layers": 12
    },
    "bart-large": {
        "huggingface_hub": "facebook/bart-large",
        "model_type": "encoder-decoder",
        "num_layers": 24
    },
    "longformer-base": {
        "huggingface_hub": "allenai/longformer-base-4096",
        "model_type": "encoder",
        "num_layers": 12
    },
    "longformer-large": {
        "huggingface_hub": "allenai/longformer-large-4096",
        "model_type": "encoder",
        "num_layers": 24
    },
    "llama-3.2": {
        "huggingface_hub": "meta-llama/Llama-3.2-1B",
        "model_type": "decoder",
        "num_layers": 16
    },
    "llama-3.2-3B": {
        "huggingface_hub": "meta-llama/Llama-3.2-3B",
        "model_type": "decoder",
        "num_layers": 28
    },
    "llama-3.2-8B": {
        "huggingface_hub": "meta-llama/Llama-3.1-8B",
        "model_type": "decoder",
        "num_layers": 28
    },
    "gemma-2-2b-it": {
        "huggingface_hub": "google/gemma-2-2b-it",
        "model_type": "decoder",
        "num_layers": 26
    },
    "gemma-3-1b-it": {
        "huggingface_hub": "google/gemma-3-1b-it",
        "model_type": "decoder",
        "num_layers": 26
    },
    "qwen-2.5-7b": {
        "huggingface_hub": "Qwen/Qwen2.5-7B-Instruct",
        "model_type": "decoder",
        "num_layers": 28
    },
    "qwen-2.5-3b": {
        "huggingface_hub": "Qwen/Qwen2.5-3B-Instruct",
        "model_type": "decoder",
        "num_layers": 36
    },
    "qwen-2.5-0.5": {
        "huggingface_hub": "Qwen/Qwen2.5-0.5B-Instruct",
        "model_type": "decoder",
        "num_layers": 24
    },
    "qwen-2.5-1.5": {
        "huggingface_hub": "Qwen/Qwen2.5-1.5B-Instruct",
        "model_type": "decoder",
        "num_layers": 28
    },
    "qwen-2.5-1.5-awq": {
        "huggingface_hub": "Qwen/Qwen2.5-1.5B-Instruct-AWQ",
        "model_type": "decoder",
        "num_layers": 28
    },
    "qwen-2.5-3b-awq": {
        "huggingface_hub": "Qwen/Qwen2.5-3B-Instruct-AWQ",
        "model_type": "decoder",
        "num_layers": 36
    },
    "qwen-2.5-1.5-4bit": {
        "huggingface_hub": "Qwen/Qwen2.5-1.5B-Instruct-GPTQ-Int4",
        "model_type": "decoder",
        "num_layers": 28
    },
    "qwen-2.5-1.5-8bit": {
        "huggingface_hub": "Qwen/Qwen2.5-1.5B-Instruct-GPTQ-Int8",
        "model_type": "decoder",
        "num_layers": 28
    },
    "qwen-2.5-3b-4bit": {
        "huggingface_hub": "Qwen/Qwen2.5-3B-Instruct-GPTQ-Int4",
        "model_type": "decoder",
        "num_layers": 36
    },
    "qwen-2.5-3b-smoothquant": {
        "huggingface_hub": "stan-hua/Qwen2.5-3B-Instruct-LC-SmoothQuant-RTN-W8A8",
        "model_type": "decoder",
        "num_layers": 36
    },
    "qwen-2.5-3b-base": {
        "huggingface_hub": "Qwen/Qwen2.5-3B-Instruct",
        "model_type": "decoder",
        "num_layers": 36
    },
    "phi-3-3B": {
        "huggingface_hub": "microsoft/Phi-3-mini-4k-instruct",
        "model_type": "decoder",
        "num_layers": 32
    },
    "phi-3-7B": {
        "huggingface_hub": "microsoft/Phi-3-small-4k-instruct",
        "model_type": "decoder",
        "num_layers": 32
    },
    "deepseek-r1-qwen": {
        "huggingface_hub": "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
        "model_type": "decoder",
        "num_layers": 28
    },
    "deepseek-r1-qwen7b": {
        "huggingface_hub": "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
        "model_type": "decoder",
        "num_layers": 28
    },
    "stablelm-3b": {
        "huggingface_hub": "stabilityai/stablelm-zephyr-3b",
        "model_type": "decoder",
        "num_layers": 32
    },
    "stablelm-1.6b": {
        "huggingface_hub": "stabilityai/stablelm-2-zephyr-1_6b",
        "model_type": "decoder",
        "num_layers": 32
    },
    "stablelm-7b": {
        "huggingface_hub": "HuggingFaceH4/zephyr-7b-beta",
        "model_type": "decoder",
        "num_layers": 32
    },
    "minicpm-2b": {
        "huggingface_hub": "openbmb/MiniCPM-2B-sft-bf16",
        "model_type": "decoder",
        "num_layers": 40
    },
    "mbert-base": {
        "huggingface_hub": "google-bert/bert-base-multilingual-cased",
        "model_type": "encoder",
        "num_layers": 12
    }
}
